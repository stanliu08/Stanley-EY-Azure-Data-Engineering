{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3f1f4f",
   "metadata": {},
   "source": [
    "Where does the cleaning differ between the datasets?\n",
    "\n",
    "    We approached the cleaning in very similar ways. We skipped the first row that contained the source link. We handled any cells that had empty values by either dropping or renaming strings to “Unknown.”\n",
    "\n",
    "    Pratik’s Dataset\n",
    "    The dataset looks very similar to Stanley’s dataset\n",
    "    used a groupby on directors, which was another way to get counts\n",
    "    tried to print specific mean values for IMDB ratings after groupby\n",
    "\n",
    "    Stanley’s Dataset\n",
    "    Dropped columns that didn’t have analytical values. Used a set to get the count of unique genres, different from Pratik’s\n",
    "    Separated genre counts into individual (Drama, Thriller) would be separated into (Drama) and (Thriller)\n",
    "\n",
    "\n",
    "\n",
    "    Afred’s Dataset\n",
    "    The dataset has additional columns, like certificates and stars in the movie\n",
    "    Dropped columns that didn’t have analytical values\n",
    "\n",
    "    Individual Work Overview\n",
    "    We all had to skip the first row of the data set that contained the source link\n",
    "    We all did something similar with getting the director counts by using value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Discuss as a group (and denote in your final markdown) how you would handle data cleaning if you were given all 3 datasets to start?\n",
    "    \n",
    "    We would probably think of what should act as the key when we merge everything. In our case, we use the Title of the movie as the basis of merging everything\n",
    "    We also have to consider which columns we keep and drop\n",
    "    The steps we would take would be:\n",
    "    Clean the individual datasets\n",
    "    Merge them based on their Title matches\n",
    "    Clean the merged datasets, remove/rename columns\n",
    "    Ensure no empty values exist\n",
    "    Are there any places in your cleaning where you could add functions for more efficient (and possibly automated) cleaning\n",
    "    I think we could add a function in the initial setup of the cleaning process, where we skipped the first row that contains the source link\n",
    "    Another function we can create is one that can remove null and duplicate values by passing in a dataframe\n",
    "\n",
    "\n",
    "What's different about the movie sets?\n",
    "\n",
    "    Stanley’s and Pratik’s datasets were very similar; they had the same column number, column names, and entries. Alfred’s dataset had additional columns like stars in the movie, gross earnings, certificates (age rating), meta rating, movie overview, and different values in the number of votes. We had to consider these differences when we combined our three datasets.\n",
    "\n",
    "\n",
    "    Using these datasets, what types of questions/analytics about the data could be answered or addressed?\n",
    "\n",
    "\n",
    "    Is there any data you wish these datasets had? (Are there any relevant attributes you think would provide further insight) \n",
    "\n",
    "    Having data on the cost to make the movie would be good. We can use this with the grosses to see the profit margins, which can provide more insight\n",
    "    We found that there was data online for popularity, we think this could be helpful in\n",
    "\n",
    "    If you answered yes to this, do a brief online search to see if you can find some data to combine with what we have (optional)\n",
    "\n",
    "    We got more data on the costs to make the movie from https://www.kaggle.com/datasets/utkarshx27/movies-dataset?resource=download\n",
    "    We also created a function that takes a title as a parameter and returns the stars and directors who worked on that film\n",
    "\n",
    "\n",
    "    Reflections/Questions we had to ask ourselves\n",
    "    When combining our three datasets, would it be best to combine the uncleaned original datasets or the three cleaned datasets?\n",
    "\n",
    "\n",
    "\n",
    "SECTION 2\n",
    "\n",
    "    Process of the Aggregated dataset/Conclusion\n",
    "    Loaded 3 separated datasets\n",
    "    Cleaned the individual datasets\n",
    "    We merged using an inner join based on the Title\n",
    "    1000 rows across 3 datasets become 557 matching entries in the aggregated dataset\n",
    "    Cleaned for duplicate columns\n",
    "    Removed and renamed columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427840e",
   "metadata": {},
   "source": [
    "COMBINING DATA SETS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.set_option('display.max_columns', None) # Allows us to see all of the columns without any truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa61dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the Different File for the DataFrames\n",
    "par = pd.read_csv(r'..\\Data\\Movie Data\\IMDB_Top1000_1996_2024_reddit.csv', header = 1)\n",
    "stn = pd.read_csv(r'..\\Data\\Movie Data\\imdb-top-rated-movies-user-rated-kaggle.csv', header = 1 )\n",
    "alf = pd.read_csv(r'..\\Data\\Movie Data\\imdb_top_1000.csv', header = 1)\n",
    "cost = pd.read_csv(r'..\\Data\\Movie Data\\movie_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30639a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged the DataFrames\n",
    "superDF = pd.merge(par,stn)\n",
    "# Renamed the Series in third DataFrame to merge on common Series Name\n",
    "alf = alf.rename(columns={'Series_Title':'Title'})\n",
    "superDF = pd.merge(superDF,alf, on = 'Title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING \n",
    "# Drop: Original Title, Runtime, IMDB_Rating, Released_Year, Genre, Director\n",
    "# Rename: No_of_votes -> IMDB Votes, Num Votes -> Total Votes, Poster_Link -> Review Link\n",
    "\n",
    "superDF = superDF.rename(columns = {'No_of_Votes': 'IMDB Votes', 'Num Votes': 'Total Votes', 'Poster_Link': 'Review Link'})\n",
    "superDF.drop({'Original Title', 'Runtime', 'IMDB_Rating', 'Released_Year', 'Genre', 'Director'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a more user friendly presentation of the Series in the DataFrame\n",
    "new_order = [\n",
    "    'Position',\n",
    "    'Title',\n",
    "    'Title Type',\n",
    "    'Certificate',\n",
    "    'Year',\n",
    "    'Release Date',\n",
    "    'Directors',\n",
    "    'Star1',\n",
    "    'Star2',\n",
    "    'Star3',\n",
    "    'Star4',\n",
    "    'Genres',\n",
    "    'Runtime (mins)',\n",
    "    'Overview',\n",
    "    'IMDb Rating',\n",
    "    'Meta_score',\n",
    "    'Total Votes',\n",
    "    'IMDB Votes',\n",
    "    'Gross',\n",
    "    'URL',\n",
    "    'Review Link'\n",
    "]\n",
    "\n",
    "superDF = superDF[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e215fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "superDF[\"Release Date\"] = pd.to_datetime(superDF[\"Release Date\"],errors=\"coerce\")\n",
    "superDF = superDF.dropna(subset=[\"Release Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d43fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = cost[['original_title','budget','original_language', 'popularity']]\n",
    "cost = cost.rename(columns = {'original_title':'Title','original_language': 'language'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the Stars with Directors\n",
    "def directorWithStars(title):\n",
    "\n",
    "    stars = superDF[superDF['Title'] == title].loc[:,['Star1','Star2','Star3','Star4']]\n",
    "    director = superDF[superDF['Title'] == title].loc[:, 'Directors']\n",
    "    \n",
    "    return list(stars.iloc[0]), director.iloc[0]\n",
    "    \n",
    "a = directorWithStars('12 Angry Men')\n",
    "print(f\"Stars: {a[0]}\")\n",
    "print(f\"Directors: {a[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5174e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "superDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sortD = superDF.groupby('Directors')['IMDb Rating'].count()\n",
    "\n",
    "sortD = sortD.sort_values(ascending = False)\n",
    "directors = sortD.head(10)\n",
    "\n",
    "directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3686b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(directors.index, directors.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Director')\n",
    "plt.ylabel('Amount of Films')\n",
    "plt.title('Total Films by Director')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
